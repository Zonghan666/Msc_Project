{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T22:43:13.875977Z",
     "start_time": "2018-07-08T22:43:07.076284Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nets import *\n",
    "from utils import *\n",
    "from loss import *\n",
    "from train import batch_generator, read_data_from_batch\n",
    "import parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T22:43:13.886362Z",
     "start_time": "2018-07-08T22:43:13.878498Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_path = 'path/img_train_path.txt'\n",
    "y_path = 'path/label_train_path.txt'\n",
    "yolo_weight = 'weights/yolov3.weights'\n",
    "\n",
    "learning_rate = 0.0001\n",
    "n_classes = 1\n",
    "input_shape = (416,416)\n",
    "batch_size = 2\n",
    "\n",
    "dim_0 = input_shape[0] / 32\n",
    "dim_1 = dim_0 * 2\n",
    "dim_2 = dim_1 * 2\n",
    "dim = (dim_0**2 + dim_1**2 + dim_2**2) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T22:43:13.900305Z",
     "start_time": "2018-07-08T22:43:13.889378Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_x = tf.placeholder(tf.float32, [batch_size, input_shape[0], input_shape[1], 3])\n",
    "tf_y = tf.placeholder(tf.float32, [batch_size, dim, 5+n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T22:43:20.468827Z",
     "start_time": "2018-07-08T22:43:13.905427Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with tf.variable_scope('detector'):\n",
    "    detections, raw_output = yolo_v3(input_tensor=tf_x, n_classes=n_classes)\n",
    "    #load_ops = load_weight(var_list=tf.global_variables(scope='detector'), weight_file=yolo_weight, for_training=False)\n",
    "\n",
    "    boxes = get_boxes(detections, n_classes, input_shape)\n",
    "\n",
    "    xy_loss, wh_loss, confidence_loss, class_loss = get_loss(raw_output=raw_output, y_true=tf_y, input_shape=input_shape)\n",
    "\n",
    "    loss = xy_loss + wh_loss + confidence_loss + class_loss\n",
    "\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T22:43:23.301513Z",
     "start_time": "2018-07-08T22:43:21.705180Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T22:44:59.495750Z",
     "start_time": "2018-07-08T22:43:27.764301Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for step in range(10):\n",
    "    \n",
    "    batches = batch_generator(x_path, y_path, batch_size)\n",
    "    n_batch = len(batches)\n",
    "    \n",
    "    loss_0 = loss_1 = loss_2 = loss_3 = 0\n",
    "\n",
    "    for batch in batches:\n",
    "        b_x, b_y = read_data_from_batch(batch, input_shape, parameter._ANCHORS, n_classes)\n",
    "\n",
    "        _, xy_loss_, wh_loss_, confidence_loss_, class_loss_ = sess.run([train_op, xy_loss, wh_loss, confidence_loss, class_loss], \n",
    "                                                                         feed_dict={tf_x:b_x, tf_y:b_y})\n",
    "        \n",
    "        print(i)\n",
    "        loss_0 += xy_loss_\n",
    "        loss_1 += wh_loss_\n",
    "        loss_2 += confidence_loss_\n",
    "        loss_3 += class_loss_\n",
    "    \n",
    "    loss_0 /= n_batch\n",
    "    loss_1 /= n_batch\n",
    "    loss_2 /= n_batch\n",
    "    loss_3 /= n_batch\n",
    "        \n",
    "    print('Step:', step, '| xy_loss: %.4f' % loss_0 , '| wh_loss: %.4f' % loss_1, '| confidence_loss: %.4f' % loss_2, '| class_loss: %.4f' % loss_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T21:53:12.809173Z",
     "start_time": "2018-07-03T21:53:11.777306Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T21:56:02.690751Z",
     "start_time": "2018-07-03T21:56:00.822836Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver.save(sess, save_path='check/', write_meta_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T14:08:47.182370Z",
     "start_time": "2018-07-08T14:08:47.029782Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches = batch_generator(x_path, y_path, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
